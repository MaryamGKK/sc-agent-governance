{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "806ac577",
   "metadata": {},
   "source": [
    "# Lab 1: Build an Agent with LangGraph\n",
    "\n",
    "This notebook demonstrates how easily sensitive information can be exposed when building GenAI agents without governance. We'll simulate a customer support chatbot with no access controls, sandboxing, or observability. The goal is to highlight key governance risks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab73285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (if running locally)\n",
    "!pip install langgraph langchain-openai mlflow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec7a241e-e715-4565-91f4-998c1fe03b48",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Set your OpenAI API key\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f961ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup LangGraph and OpenAI LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "llm = ChatOpenAI(temperature=0,model=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f47a1a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tool with shipment info (sensitive)\n",
    "@tool\n",
    "def get_order_info(email: str) -> str:\n",
    "    \"\"\"Returns full order details including address, delivery instructions, and total amount.\"\"\"\n",
    "    return f\"Order for {email}: ðŸ“¦ iPhone 15 Pro to 1234 Maple St, Apt 101, with delivery instructions: 'leave at door'. Total: $1,099.\"\n",
    "\n",
    "tools = [get_order_info]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c92ce2a1-e3f9-41e5-bf26-1e000f774471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Create a prompt for the ReAct agent\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    ")\n",
    "\n",
    "# Create the agent with the prompt\n",
    "agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "def run_agent(state: dict) -> dict:\n",
    "    \"\"\"Run the agent with an input state that includes an 'email' key.\"\"\"\n",
    "    user_input = state.get(\"email\", \"\")\n",
    "    if not user_input:\n",
    "        return {\"response\": \"No email provided.\"}\n",
    "    response = agent_executor.invoke({\"input\": user_input})\n",
    "    return {\"response\": response[\"output\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6eca1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The question seems to be an email address. It's likely that the user wants to know the order details associated with this email. I should use the get_order_info function to retrieve this information.\n",
      "Action: get_order_info\n",
      "Action Input: john.doe@example.com\u001b[0m\u001b[36;1m\u001b[1;3mOrder for john.doe@example.com: ðŸ“¦ iPhone 15 Pro to 1234 Maple St, Apt 101, with delivery instructions: 'leave at door'. Total: $1,099.\u001b[0m\u001b[32;1m\u001b[1;3mI now have the order details for the email address provided.\n",
      "Final Answer: The order for john.doe@example.com includes an iPhone 15 Pro to be delivered to 1234 Maple St, Apt 101, with delivery instructions to 'leave at door'. The total amount for the order is $1,099.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The order for john.doe@example.com includes an iPhone 15 Pro to be delivered to 1234 Maple St, Apt 101, with delivery instructions to 'leave at door'. The total amount for the order is $1,099.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# Build LangGraph with a single ReAct agent node\n",
    "builder = StateGraph(dict)  # Explicitly define the state type\n",
    "builder.add_node(\"agent\", run_agent)\n",
    "builder.set_entry_point(\"agent\")\n",
    "builder.set_finish_point(\"agent\")\n",
    "graph = builder.compile()\n",
    "\n",
    "# Simulate a possible customer query\n",
    "output = graph.invoke({\"email\": \"john.doe@example.com\"})\n",
    "print(output[\"response\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318d7236",
   "metadata": {},
   "source": [
    "## Discussion: What Went Wrong?\n",
    "- No access controls or authentication on tools\n",
    "- No function validation or logging\n",
    "- Exposed sensitive shipment data\n",
    "- No audit trail or MLflow observability\n",
    "\n",
    "We'll address these governance gaps in Lab 2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
