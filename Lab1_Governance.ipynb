{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46fa4882-3406-4a25-bf1c-dd5ff7728372",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Lab 1: Building the Governance Foundation\n",
    "\n",
    "In this hands-on lab, you'll learn how to build AI agents that respect data governance policies using Databricks Unity Catalog. We'll create an HR Analyst agent that can answer questions about employees, compensation, and policies while automatically enforcing security controls through governance and identity best practices.\n",
    "\n",
    "### Lab Structure\n",
    "**Lab 1: Building the Governance Foundation**\n",
    "- Set up\n",
    "    - Make sure you are connected to `serverless` compute\n",
    "    - Create HR tables in `clientcare.hr_data` from GitHub\n",
    "    - Apply data classifications using Unity Catalog tags\n",
    "    - Create a view with anonymization and filtering\n",
    "    - Create a `Devs` Group and `hr_data_analysts` service principal\n",
    "    - Grant appropriate permissions on our view \n",
    "    - Implement table-level column masking for SSN\n",
    "    - Build functions for querying tables\n",
    "\n",
    "**Lab 2: Creating the AI Agent**\n",
    "- Compile the HR Analyst agent \n",
    "- Bind the LLM, system prompt, and tools \n",
    "\n",
    "**Lab 3: Agent Evaluation and Testing**\n",
    "- Register the agent model in MLflow\n",
    "- Evaluate agent responses using LLM as a judge\n",
    "- Deploy the agent as a job on behalf of the service principal\n",
    "- Test the complete governance stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0451cb73-aa09-4e0e-baac-577474ad883c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Initial Setup and Data Verification**\n",
    "\n",
    "Let's start by verifying our environment and examining the data classifications we've already applied.\n",
    "\n",
    "_Background for those new to Databricks_\n",
    "\n",
    "- We use `spark.sql()` for all governance OPERATIONS (CREATE VIEW, GRANT, etc.)\n",
    "- We use `pandas.DataFrame()` for showing results in a nice format\n",
    "- We use the Databricks SDK (`WorkspaceClient`) for workspace verification\n",
    "\n",
    "**Implementing Unity Catalog Governance: Available Methods**\n",
    "\n",
    "1. **Pure SQL** - The standard approach for production environments \n",
    "2. **Spark SQL in Python** - SQL commands as strings in Python (what we'll use)\n",
    "3. **PySpark DataFrame API** - The Pythonic approach for queries\n",
    "4. **Databricks SDK** - For reading data, automation and verification\n",
    "5. **REST API** - For external integrations and CI/CD pipelines\n",
    "6. **Terraform** - Infrastructure as Code approach for version-controlled, repeatable deployments\n",
    "\n",
    "In this lab, we'll primarily use **Spark SQL in Python** (#2) for governance operations and the **SDK** (#4) for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "535067a0-b285-4e56-916c-fb07123f2849",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set our working environment\n",
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import pandas as pd\n",
    "\n",
    "# Use the workspace client to retrieve information about the current user\n",
    "w = WorkspaceClient()\n",
    "\n",
    "# Catalog and schema names\n",
    "catalog_name = \"clientcare\"\n",
    "schema_name = \"hr_data\"\n",
    "\n",
    "# Create the catalog if it does not exist\n",
    "spark.sql(\n",
    "    f\"CREATE CATALOG IF NOT EXISTS {catalog_name}\"\n",
    ")\n",
    "\n",
    "# Create the schema in the catalog\n",
    "spark.sql(\n",
    "    f\"CREATE SCHEMA IF NOT EXISTS {catalog_name}.{schema_name}\"\n",
    ")\n",
    "\n",
    "# Set widgets for catalog and schema\n",
    "dbutils.widgets.text(\"catalog_name\", defaultValue=catalog_name, label=\"Catalog Name\")\n",
    "dbutils.widgets.text(\"schema_name\", defaultValue=schema_name, label=\"Schema Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d0d01c3-4ef5-4d8b-84a7-7e25a81f9e34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables created successfully\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import io\n",
    "\n",
    "base_url = \"https://raw.githubusercontent.com/databricks/tmm/main/Governance-lab/data\"\n",
    "csv_files = {\n",
    "    \"compensation_data\": f\"{base_url}/compensation_data.csv\",\n",
    "    \"employee_records\": f\"{base_url}/employee_records.csv\", \n",
    "    \"hr_cases\": f\"{base_url}/hr_cases.csv\",\n",
    "    \"internal_procedures\": f\"{base_url}/internal_procedures.csv\",\n",
    "    \"performance_reviews\": f\"{base_url}/performance_reviews.csv\",\n",
    "    \"public_policies\": f\"{base_url}/public_policies.csv\"\n",
    "}\n",
    "\n",
    "# Download and load each CSV file\n",
    "for table_name, url in csv_files.items():\n",
    "    # Download CSV data\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Read CSV into pandas DataFrame\n",
    "    df = pd.read_csv(io.StringIO(response.text))\n",
    "    \n",
    "    # Convert to Spark DataFrame and write to table\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "    spark_df.write.mode(\"overwrite\").saveAsTable(f\"{catalog_name}.hr_data.{table_name}\")\n",
    "print(\"Tables created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19473b9f-86f5-4323-ba67-a8f104cc1fcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clientcare catalog and hr_data schema have been created\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_name}\")\n",
    "print(f\"{catalog_name} catalog and {schema_name} schema have been created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91a13a04-bab0-468e-b09b-901e80e51743",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_id</th><th>first_name</th><th>last_name</th><th>department</th><th>ssn</th><th>phone</th><th>email</th><th>hire_date</th><th>base_salary</th><th>bonus</th><th>stock_options</th></tr></thead><tbody><tr><td>E001</td><td>John</td><td>Smith</td><td>Engineering</td><td>123-45-6789</td><td>555-0101</td><td>john.smith@company.com</td><td>2020-01-15</td><td>120000</td><td>15000</td><td>5000</td></tr><tr><td>E002</td><td>Sarah</td><td>Johnson</td><td>Sales</td><td>234-56-7890</td><td>555-0102</td><td>sarah.j@company.com</td><td>2019-03-22</td><td>85000</td><td>12000</td><td>2000</td></tr><tr><td>E003</td><td>Michael</td><td>Brown</td><td>HR</td><td>345-67-8901</td><td>555-0103</td><td>m.brown@company.com</td><td>2021-06-10</td><td>95000</td><td>10000</td><td>3000</td></tr><tr><td>E004</td><td>Emily</td><td>Davis</td><td>Engineering</td><td>456-78-9012</td><td>555-0104</td><td>emily.d@company.com</td><td>2022-02-28</td><td>110000</td><td>14000</td><td>4000</td></tr><tr><td>E005</td><td>Robert</td><td>Wilson</td><td>Marketing</td><td>567-89-0123</td><td>555-0105</td><td>r.wilson@company.com</td><td>2020-11-05</td><td>90000</td><td>11000</td><td>2500</td></tr><tr><td>E006</td><td>Lisa</td><td>Anderson</td><td>Sales</td><td>678-90-1234</td><td>555-0106</td><td>l.anderson@company.com</td><td>2021-08-14</td><td>88000</td><td>11500</td><td>2200</td></tr><tr><td>E007</td><td>David</td><td>Taylor</td><td>HR</td><td>789-01-2345</td><td>555-0107</td><td>d.taylor@company.com</td><td>2019-12-03</td><td>92000</td><td>9500</td><td>2800</td></tr><tr><td>E008</td><td>Jennifer</td><td>Martin</td><td>Engineering</td><td>890-12-3456</td><td>555-0108</td><td>j.martin@company.com</td><td>2023-01-20</td><td>105000</td><td>13000</td><td>3500</td></tr><tr><td>E009</td><td>William</td><td>Garcia</td><td>Marketing</td><td>901-23-4567</td><td>555-0109</td><td>w.garcia@company.com</td><td>2022-05-17</td><td>87000</td><td>10500</td><td>2400</td></tr><tr><td>E010</td><td>Maria</td><td>Rodriguez</td><td>Finance</td><td>012-34-5678</td><td>555-0110</td><td>m.rodriguez@company.com</td><td>2020-09-08</td><td>115000</td><td>16000</td><td>4500</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "E001",
         "John",
         "Smith",
         "Engineering",
         "123-45-6789",
         "555-0101",
         "john.smith@company.com",
         "2020-01-15",
         120000,
         15000,
         5000
        ],
        [
         "E002",
         "Sarah",
         "Johnson",
         "Sales",
         "234-56-7890",
         "555-0102",
         "sarah.j@company.com",
         "2019-03-22",
         85000,
         12000,
         2000
        ],
        [
         "E003",
         "Michael",
         "Brown",
         "HR",
         "345-67-8901",
         "555-0103",
         "m.brown@company.com",
         "2021-06-10",
         95000,
         10000,
         3000
        ],
        [
         "E004",
         "Emily",
         "Davis",
         "Engineering",
         "456-78-9012",
         "555-0104",
         "emily.d@company.com",
         "2022-02-28",
         110000,
         14000,
         4000
        ],
        [
         "E005",
         "Robert",
         "Wilson",
         "Marketing",
         "567-89-0123",
         "555-0105",
         "r.wilson@company.com",
         "2020-11-05",
         90000,
         11000,
         2500
        ],
        [
         "E006",
         "Lisa",
         "Anderson",
         "Sales",
         "678-90-1234",
         "555-0106",
         "l.anderson@company.com",
         "2021-08-14",
         88000,
         11500,
         2200
        ],
        [
         "E007",
         "David",
         "Taylor",
         "HR",
         "789-01-2345",
         "555-0107",
         "d.taylor@company.com",
         "2019-12-03",
         92000,
         9500,
         2800
        ],
        [
         "E008",
         "Jennifer",
         "Martin",
         "Engineering",
         "890-12-3456",
         "555-0108",
         "j.martin@company.com",
         "2023-01-20",
         105000,
         13000,
         3500
        ],
        [
         "E009",
         "William",
         "Garcia",
         "Marketing",
         "901-23-4567",
         "555-0109",
         "w.garcia@company.com",
         "2022-05-17",
         87000,
         10500,
         2400
        ],
        [
         "E010",
         "Maria",
         "Rodriguez",
         "Finance",
         "012-34-5678",
         "555-0110",
         "m.rodriguez@company.com",
         "2020-09-08",
         115000,
         16000,
         4500
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ssn",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "phone",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "email",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "hire_date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "base_salary",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "bonus",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "stock_options",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# This demonstrates the current security risk - without proper governance controls,\n",
    "# all sensitive data (SSNs, salaries, bonuses) is fully exposed to any user with table access\n",
    "# In a real production environment, this would be a major compliance violation\n",
    "\n",
    "display(spark.sql(\"\"\"\n",
    "   SELECT \n",
    "       e.employee_id,\n",
    "       e.first_name,\n",
    "       e.last_name,\n",
    "       e.department,\n",
    "       e.ssn,\n",
    "       e.phone,\n",
    "       e.email,\n",
    "       e.hire_date,\n",
    "       c.base_salary,\n",
    "       c.bonus,\n",
    "       c.stock_options\n",
    "   FROM employee_records e\n",
    "   JOIN compensation_data c ON e.employee_id = c.employee_id\n",
    "   ORDER BY e.employee_id\n",
    "   LIMIT 10\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84c9ee12-d6b6-4bad-a12a-0ee43394f092",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Apply Data Classifications and Tags**\n",
    "\n",
    "First, we'll tag our tables with sensitivity levels. Table properties are metadata tags that help classify data sensitivity without changing the actual data structure:\n",
    "\n",
    "- Metadata key-value pairs attached to tables\n",
    "- Used by governance tools to understand data sensitivity\n",
    "- Don't affect table structure or data\n",
    "- Can be queried programmatically for compliance\n",
    "\n",
    "Our data classification schema:\n",
    " - Public: Anyone can access (company policies)\n",
    " - Internal: Employees only (procedures)\n",
    " - Confidential: Limited access (employee records, reviews)\n",
    " - Restricted: Highly sensitive (compensation, HR cases)\n",
    "\n",
    "Adding classification tags like \"Confidential,\" \"Restricted,\" or \"Public\" to Unity Catalog serve as metadata that make your data assets more manageable, secure, and compliant with both internal policies and external regulations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2b7cd4e-597b-418e-b586-444e140f5d9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Classified clientcare.hr_data.employee_records as Confidential\n✓ Classified clientcare.hr_data.compensation_data as Restricted\n✓ Classified clientcare.hr_data.performance_reviews as Confidential\n✓ Classified clientcare.hr_data.hr_cases as Restricted\n✓ Classified clientcare.hr_data.public_policies as Public\n✓ Classified clientcare.hr_data.internal_procedures as Internal\n"
     ]
    }
   ],
   "source": [
    "# Define the classification tags for each table\n",
    "tables_config = [\n",
    "    (\"clientcare.hr_data.employee_records\", \"Confidential\", \"true\"),\n",
    "    (\"clientcare.hr_data.compensation_data\", \"Restricted\", \"true\"),\n",
    "    (\"clientcare.hr_data.performance_reviews\", \"Confidential\", \"true\"),\n",
    "    (\"clientcare.hr_data.hr_cases\", \"Restricted\", \"true\"),\n",
    "    (\"clientcare.hr_data.public_policies\", \"Public\", \"false\"),\n",
    "    (\"clientcare.hr_data.internal_procedures\", \"Internal\", \"false\")\n",
    "]\n",
    "\n",
    "# Apply classifications using tags (tags are metadata)\n",
    "for table_name, classification, has_pii in tables_config:\n",
    "    spark.sql(f\"\"\"\n",
    "        ALTER TABLE {table_name} SET TAGS (\n",
    "            'classification' = '{classification}',\n",
    "            'contains_pii' = '{has_pii}'\n",
    "        )\n",
    "    \"\"\")\n",
    "    print(f\"✓ Classified {table_name} as {classification}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdf093b4-5618-4fd5-8194-b563077c67e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Agent Permissions & Agent Access Requirements**\n",
    "Now that we've classified our data, let's design the right access level for our HR analytics agent through purpose-built views.\n",
    "\n",
    "**Key Decision:** The agent needs a specialized view - \"Data Analyst View\" - that provides analytical capabilities while protecting individual privacy.\n",
    "\n",
    "What the Agent Needs vs. Doesn't Need:\n",
    "| Data Type | HR Admin Sees | Manager Sees | Data Analyst | Why? |\n",
    "|-----------|---------------|--------------|------------------|------|\n",
    "| **Names** | ✅ John Smith | ✅ John Smith | ❌ Anonymous IDs | Prevents bias, protects privacy |\n",
    "| **SSN** | ✅ 123-45-6789 | ❌ Hidden | ❌ Hidden | No analytical value |\n",
    "| **Salary** | ✅ $120,000 | ❌ Hidden | ✅ $120,000 | Needed for accurate statistics |\n",
    "| **Department** | ✅ Engineering | ✅ Engineering | ✅ Engineering | Needed for grouping |\n",
    "| **Performance** | ✅ 4.5 | ✅ 4.5 | ✅ 4.5 | Needed for correlation analysis |\n",
    "| **Email** | ✅ john@company.com | ✅ john@company.com | ❌ Hidden | No analytical value |\n",
    "| **Phone** | ✅ 555-1234 | ✅ 555-1234 | ❌ Hidden | No analytical value |\n",
    "\n",
    "The Agent's Mission:\n",
    "Answer questions like:\n",
    "- \"What's the salary distribution in Engineering?\"\n",
    "- \"Is there pay equity across departments?\"\n",
    "- \"What's the correlation between performance and compensation?\"\n",
    "\n",
    "WITHOUT being able to answer:\n",
    "- \"What's John Smith's salary?\"\n",
    "- \"Who are the top 5 highest paid employees?\"\n",
    "- \"Show me SSNs for employees making over $100k\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14dd10fc-f169-4790-afed-37b8c7e0a227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Create Classification-Aware View**\n",
    "\n",
    "Now we'll create the `data_analyst_view` that automatically provide appropriate data access based on our classifications. This view designed for analysts will have Anonymous IDs + full compensation data for statistical analysis.\n",
    "\n",
    "**Why Views for Access Control:**\n",
    "- **Simplicity**: Instead of complex masking rules for every possible user type, create purpose-built views\n",
    "- **Clarity**: Each view has a clear business purpose and user type\n",
    "- **Maintainability**: Easier to understand and modify than intricate permission matrices\n",
    "- **Performance**: Views are optimized SQL - no runtime masking overhead\n",
    "- **Security Layer**: In Databricks, views act as your security layer since we grant permissions directly to principals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f42c0de-167d-45bc-a5a6-8596c9dbf798",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created data_analyst_view: Anonymous IDs + full compensation data (enhanced anonymization)\n"
     ]
    }
   ],
   "source": [
    "# DATA ANALYST VIEW - For statistical analysis \n",
    "\n",
    "# Key features: Anonymous employee IDs, full salary access, excludes Legal dept\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE VIEW data_analyst_view AS\n",
    "SELECT \n",
    "    CONCAT('EMP_', LPAD(e.employee_id, 6, '0')) as anonymous_id,  -- EMP_000001 format\n",
    "    e.department,\n",
    "    YEAR(e.hire_date) as hire_year,                            -- Year only for better anonymization\n",
    "    c.base_salary,                                              -- Full salary for analytics\n",
    "    c.bonus,\n",
    "    c.stock_options,\n",
    "    YEAR(c.effective_date) as comp_year,\n",
    "    pr.rating,\n",
    "    QUARTER(pr.review_date) as review_quarter,\n",
    "    YEAR(pr.review_date) as review_year\n",
    "    -- Removed pr.comments to prevent identifying information\n",
    "FROM employee_records e\n",
    "LEFT JOIN compensation_data c ON e.employee_id = c.employee_id\n",
    "LEFT JOIN performance_reviews pr ON e.employee_id = pr.employee_id\n",
    "WHERE e.department != 'Legal'  -- Exclude Legal for compliance reasons\n",
    "\"\"\")\n",
    "print(\"✓ Created data_analyst_view: Anonymous IDs + full compensation data (enhanced anonymization)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1de52aa7-c25d-4b5d-8ffa-f34aa69ae025",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Configure Group Permissions**\n",
    "\n",
    "Now we'll grant permissions to the `Dev` group you have created (which is the group that you've added the service principal `HR_data_analyst` to -- in order to inherit the groups permission). \n",
    "\n",
    "This implements the principle of least privilege - the group only gets access to anonymized, aggregated data, never raw employee records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "503407d1-a4ed-4811-a7a7-df8863905b5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>directGroup</th></tr></thead><tbody><tr><td>admins</td><td>null</td></tr><tr><td>Devs</td><td>null</td></tr><tr><td>users</td><td>null</td></tr><tr><td>test-shubham</td><td>null</td></tr><tr><td>deployment_devs</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "admins",
         null
        ],
        [
         "Devs",
         null
        ],
        [
         "users",
         null
        ],
        [
         "test-shubham",
         null
        ],
        [
         "deployment_devs",
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "directGroup",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Confirmed: Devs group is available\n"
     ]
    }
   ],
   "source": [
    "# Verify the Devs group exists\n",
    "groups_df = spark.sql(\"SHOW GROUPS\")\n",
    "display(groups_df)\n",
    "print(\"✅ Confirmed: Devs group is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c91bf6f-2f21-4ec4-94f7-fb1ca8041975",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDCCB Verifying our governance view was created successfully...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>namespace</th><th>viewName</th><th>isTemporary</th><th>isMaterialized</th><th>isMetric</th></tr></thead><tbody><tr><td>hr_data</td><td>data_analyst_view</td><td>false</td><td>false</td><td>false</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "hr_data",
         "data_analyst_view",
         false,
         false,
         false
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "namespace",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "viewName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isTemporary",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "isMaterialized",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "isMetric",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n✅ You should see:\n   - data_analyst_view (for agents and analysts)\n"
     ]
    }
   ],
   "source": [
    "# Confirm view in the schema\n",
    "print(\"\uD83D\uDCCB Verifying our governance view was created successfully...\")\n",
    "view = spark.sql(f\"SHOW VIEWS IN {catalog_name}.{schema_name}\")\n",
    "display(view)\n",
    "\n",
    "print(\"\\n✅ You should see:\")\n",
    "print(\"   - data_analyst_view (for agents and analysts)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf168de0-fb38-451f-8716-42bc5db5c193",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Granted ALL PRIVILEGES on catalog clientcare to Devs\nThis should inherit to all schemas, tables, view, and models in the catalog\n"
     ]
    }
   ],
   "source": [
    "group_name = \"Devs\"\n",
    "\n",
    "# Grant broad permissions at catalog level\n",
    "spark.sql(f\"GRANT ALL PRIVILEGES ON CATALOG {catalog_name} TO {group_name}\")\n",
    "\n",
    "print(f\"✅ Granted ALL PRIVILEGES on catalog {catalog_name} to {group_name}\")\n",
    "print(\"This should inherit to all schemas, tables, view, and models in the catalog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1611ca7d-cb31-4601-a04d-8cfe74e2a4b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Column Masking**\n",
    "**Why implement this when we already have views?**\n",
    "\n",
    "Views can be bypassed if users gain direct table access. Column masking at the table level cannot be bypassed - it's enforced by Unity Catalog on every query, regardless of how the data is accessed.\n",
    "\n",
    "**How Table-Level Security Works:**\n",
    "- **Column Masking**: Functions run automatically transforming sensitive data based on who's viewing it\n",
    "- **Row-Level Security**: Functions can also control which rows users see (we already handled Legal department filtering in our views, but this could be done at the table level too)\n",
    "- Unity Catalog enforces these at the storage layer - users **cannot bypass** them\n",
    "- Different users see different versions of the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d56dfc6-4f1f-404f-8471-0d04678a9cb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD10 Implementing column masking for SSN field...\n✅ Column masking applied to SSN field\n\uD83D\uDD10 Defense in Depth: SSN now masked at table level\n   - Admins see full SSN\n   - hr_data_analysts group sees 'ANALYTICS_MASKED'\n   - Other users see '***-**-1234' format\n"
     ]
    }
   ],
   "source": [
    "# Implement column masking for SSN field - Defense in depth security\n",
    "print(\"\uD83D\uDD10 Implementing column masking for SSN field...\")\n",
    "\n",
    "# Create column masking function for SSN\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION {catalog_name}.{schema_name}.mask_ssn(ssn_value STRING)\n",
    "RETURNS STRING\n",
    "RETURN CASE \n",
    "    WHEN is_account_group_member('hr_data_analysts') THEN 'ANALYTICS_MASKED'\n",
    "    ELSE CONCAT('***-**-', RIGHT(ssn_value, 4))\n",
    "END\n",
    "\"\"\")\n",
    "\n",
    "# Apply the masking function to the SSN column\n",
    "spark.sql(f\"\"\"\n",
    "ALTER TABLE {catalog_name}.{schema_name}.employee_records \n",
    "ALTER COLUMN ssn \n",
    "SET MASK {catalog_name}.{schema_name}.mask_ssn\n",
    "\"\"\")\n",
    "\n",
    "print(\"✅ Column masking applied to SSN field\")\n",
    "print(\"\uD83D\uDD10 Defense in Depth: SSN now masked at table level\")\n",
    "print(\"   - Admins see full SSN\")\n",
    "print(\"   - hr_data_analysts group sees 'ANALYTICS_MASKED'\") \n",
    "print(\"   - Other users see '***-**-1234' format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e93e6a1c-87f8-4a83-b8a5-3d20fee81beb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83E\uDDEA Testing SSN column masking...\n\n\uD83D\uDC64 Current user view:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>employee_id</th><th>first_name</th><th>last_name</th><th>ssn</th><th>department</th></tr></thead><tbody><tr><td>E001</td><td>John</td><td>Smith</td><td>***-**-6789</td><td>Engineering</td></tr><tr><td>E002</td><td>Sarah</td><td>Johnson</td><td>***-**-7890</td><td>Sales</td></tr><tr><td>E003</td><td>Michael</td><td>Brown</td><td>***-**-8901</td><td>HR</td></tr><tr><td>E004</td><td>Emily</td><td>Davis</td><td>***-**-9012</td><td>Engineering</td></tr><tr><td>E005</td><td>Robert</td><td>Wilson</td><td>***-**-0123</td><td>Marketing</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "E001",
         "John",
         "Smith",
         "***-**-6789",
         "Engineering"
        ],
        [
         "E002",
         "Sarah",
         "Johnson",
         "***-**-7890",
         "Sales"
        ],
        [
         "E003",
         "Michael",
         "Brown",
         "***-**-8901",
         "HR"
        ],
        [
         "E004",
         "Emily",
         "Davis",
         "***-**-9012",
         "Engineering"
        ],
        [
         "E005",
         "Robert",
         "Wilson",
         "***-**-0123",
         "Marketing"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "employee_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "first_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ssn",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validate column masking implementation\n",
    "print(\"\uD83E\uDDEA Testing SSN column masking...\")\n",
    "\n",
    "print(\"\\n\uD83D\uDC64 Current user view:\")\n",
    "display(spark.sql(f\"\"\"\n",
    "SELECT employee_id, first_name, last_name, ssn, department \n",
    "FROM {catalog_name}.{schema_name}.employee_records \n",
    "LIMIT 5\n",
    "\"\"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4840ba80-f1f4-413d-b22b-ac728650807e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Build Secure Tools for the Agent**\n",
    "Now we'll create Unity Catalog functions that our AI agent will use to query HR data. These functions act as the interface between the agent and our governed data.\n",
    "\n",
    "**Why UC Functions for Agent Tools?**\n",
    "- **Governed Access**: Functions inherit caller permissions \n",
    "- **Query Templates**: They validate inputs and enforce safe query patterns\n",
    "- **Audit Trail**: All function calls are logged for compliance\n",
    "- **Performance**: Functions can be optimized with proper indexing and caching\n",
    "\n",
    "**Our Agent Tool Strategy:**\n",
    "We'll create two general-purpose functions that:\n",
    "1. Work exclusively with the anonymized `data_analyst_view`\n",
    "2. Return aggregated results that can answer various HR questions\n",
    "3. Prevent the agent from writing arbitrary SQL\n",
    "4. Maintain employee privacy through anonymous IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dbc6248-c526-4132-9b01-3c6390a631c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD27 Creating performance analytics function...\n✓ Created analyze_performance function\n  - Returns: avg/min/max ratings, employee count, avg tenure by department\n  - Works with: anonymized data only\n"
     ]
    }
   ],
   "source": [
    "# TOOL 1: Performance & Retention Analytics\n",
    "print(\"\uD83D\uDD27 Creating performance analytics function...\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE FUNCTION\n",
    "    {catalog_name}.{schema_name}.analyze_performance()\n",
    "    RETURNS TABLE (\n",
    "        department STRING,\n",
    "        avg_rating DOUBLE,\n",
    "        min_rating DOUBLE,\n",
    "        max_rating DOUBLE,\n",
    "        employee_count INT,\n",
    "        avg_tenure_years DOUBLE\n",
    "    )\n",
    "    COMMENT 'HR Analytics: Basic performance metrics by department'\n",
    "    RETURN (\n",
    "        SELECT \n",
    "            department,\n",
    "            AVG(rating) as avg_rating,\n",
    "            MIN(rating) as min_rating,\n",
    "            MAX(rating) as max_rating,\n",
    "            COUNT(DISTINCT anonymous_id) as employee_count,\n",
    "            AVG(YEAR(CURRENT_DATE()) - hire_year) as avg_tenure_years\n",
    "        FROM {catalog_name}.{schema_name}.data_analyst_view\n",
    "        WHERE rating IS NOT NULL\n",
    "        GROUP BY department\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "print(\"✓ Created analyze_performance function\")\n",
    "print(\"  - Returns: avg/min/max ratings, employee count, avg tenure by department\")\n",
    "print(\"  - Works with: anonymized data only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20200732-9807-44b0-ad0f-63861f897f33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD27 Creating operations analytics function...\n✓ Created analyze_operations function\n  - Returns: compensation metrics and headcount by department\n  - Maintains privacy: no individual employee data exposed\n"
     ]
    }
   ],
   "source": [
    "# TOOL 2: Department & Compensation Analytics\n",
    "print(\"\uD83D\uDD27 Creating operations analytics function...\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE FUNCTION\n",
    "    {catalog_name}.{schema_name}.analyze_operations()\n",
    "    RETURNS TABLE (\n",
    "        department STRING,\n",
    "        employee_count INT,\n",
    "        avg_salary DOUBLE,\n",
    "        avg_bonus DOUBLE,\n",
    "        avg_total_comp DOUBLE,\n",
    "        avg_stock_options INT\n",
    "    )\n",
    "    COMMENT 'HR Analytics: Department compensation and operational metrics'\n",
    "    RETURN (\n",
    "        SELECT \n",
    "            department,\n",
    "            COUNT(DISTINCT anonymous_id) as employee_count,\n",
    "            AVG(base_salary) as avg_salary,\n",
    "            AVG(bonus) as avg_bonus,\n",
    "            AVG(base_salary + bonus) as avg_total_comp,\n",
    "            AVG(stock_options) as avg_stock_options\n",
    "        FROM {catalog_name}.{schema_name}.data_analyst_view\n",
    "        WHERE base_salary IS NOT NULL\n",
    "        GROUP BY department\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "print(\"✓ Created analyze_operations function\")\n",
    "print(\"  - Returns: compensation metrics and headcount by department\")\n",
    "print(\"  - Maintains privacy: no individual employee data exposed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78eabd41-61f6-4069-a384-1fffff38f5db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDCCA Test 1: Performance Analytics by Department\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>department</th><th>avg_rating</th><th>min_rating</th><th>max_rating</th><th>employee_count</th><th>avg_tenure_years</th></tr></thead><tbody><tr><td>HR</td><td>4.25</td><td>4.2</td><td>4.3</td><td>2</td><td>5.0</td></tr><tr><td>Sales</td><td>3.8499999999999996</td><td>3.8</td><td>3.9</td><td>2</td><td>5.0</td></tr><tr><td>Finance</td><td>4.4</td><td>4.4</td><td>4.4</td><td>1</td><td>5.0</td></tr><tr><td>Marketing</td><td>3.85</td><td>3.7</td><td>4.0</td><td>2</td><td>4.0</td></tr><tr><td>Engineering</td><td>4.6000000000000005</td><td>4.5</td><td>4.7</td><td>3</td><td>3.3333333333333335</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "HR",
         4.25,
         4.2,
         4.3,
         2,
         5.0
        ],
        [
         "Sales",
         3.8499999999999996,
         3.8,
         3.9,
         2,
         5.0
        ],
        [
         "Finance",
         4.4,
         4.4,
         4.4,
         1,
         5.0
        ],
        [
         "Marketing",
         3.85,
         3.7,
         4.0,
         2,
         4.0
        ],
        [
         "Engineering",
         4.6000000000000005,
         4.5,
         4.7,
         3,
         3.3333333333333335
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "avg_rating",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "min_rating",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "max_rating",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "employee_count",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "avg_tenure_years",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDCCA Test 2: Compensation Analytics by Department\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>department</th><th>employee_count</th><th>avg_salary</th><th>avg_bonus</th><th>avg_total_comp</th><th>avg_stock_options</th></tr></thead><tbody><tr><td>HR</td><td>2</td><td>93500.0</td><td>9750.0</td><td>103250.0</td><td>2900</td></tr><tr><td>Sales</td><td>2</td><td>86500.0</td><td>11750.0</td><td>98250.0</td><td>2100</td></tr><tr><td>Finance</td><td>1</td><td>115000.0</td><td>16000.0</td><td>131000.0</td><td>4500</td></tr><tr><td>Marketing</td><td>2</td><td>88500.0</td><td>10750.0</td><td>99250.0</td><td>2450</td></tr><tr><td>Engineering</td><td>3</td><td>111666.66666666667</td><td>14000.0</td><td>125666.66666666667</td><td>4166</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "HR",
         2,
         93500.0,
         9750.0,
         103250.0,
         2900
        ],
        [
         "Sales",
         2,
         86500.0,
         11750.0,
         98250.0,
         2100
        ],
        [
         "Finance",
         1,
         115000.0,
         16000.0,
         131000.0,
         4500
        ],
        [
         "Marketing",
         2,
         88500.0,
         10750.0,
         99250.0,
         2450
        ],
        [
         "Engineering",
         3,
         111666.66666666667,
         14000.0,
         125666.66666666667,
         4166
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "employee_count",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "avg_salary",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "avg_bonus",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "avg_total_comp",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "avg_stock_options",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test 1: Performance Analytics\n",
    "print(\"\\n\uD83D\uDCCA Test 1: Performance Analytics by Department\")\n",
    "display(spark.sql(f\"SELECT * FROM {catalog_name}.{schema_name}.analyze_performance()\"))\n",
    "\n",
    "# Test 2: Operations/Compensation Analytics\n",
    "print(\"\\n\uD83D\uDCCA Test 2: Compensation Analytics by Department\")\n",
    "display(spark.sql(f\"SELECT * FROM {catalog_name}.{schema_name}.analyze_operations()\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47d0f34d-3b6f-4d54-bab0-a94c8d0058ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ✅ Governance Foundation Complete\n",
    "\n",
    "### What We've Accomplished:\n",
    "1. **Data Classification with Tagging**: Applied sensitivity labels (Public, Internal, Confidential, Restricted) to all HR tables\n",
    "\n",
    "2. **Built Classification-Aware View**: \n",
    "   - `data_analyst_view` - Anonymous IDs, year-only dates, full compensation (designed for AI agents)\n",
    "   \n",
    "3. **Configured Group-Based Access**:\n",
    "   - Set up `Dev` group with permissions on our view and functions\n",
    "   - Implemented enterprise-standard permission management\n",
    "   - Ready for both users and service principals\n",
    "\n",
    "4. **Implemented Multi-Layer Security**: \n",
    "   - Table-level SSN masking (cannot be bypassed)\n",
    "   - Row-level filtering (Legal department excluded in our view)\n",
    "   - Column-level anonymization (employee IDs → EMP_000001 format)\n",
    "\n",
    "5. **Built Secure Agent Tools**:\n",
    "   - `analyze_performance()` - Returns performance ratings and tenure by department\n",
    "   - `analyze_operations()` - Returns compensation metrics and headcount by department\n",
    "   - Both functions granted to `Dev` group\n",
    "\n",
    "\n",
    "### The governance foundation is ready. Let's build the AI agent in Lab 2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d6b04f6-be34-4b8b-b638-4ce6750b6a0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Lab1_Governance",
   "widgets": {
    "catalog_name": {
     "currentValue": "clientcare",
     "nuid": "319b271d-391c-4876-b048-93317428f30d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "clientcare",
      "label": "Catalog Name",
      "name": "catalog_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "clientcare",
      "label": "Catalog Name",
      "name": "catalog_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema_name": {
     "currentValue": "hr_data",
     "nuid": "6cf6eb79-d864-4661-94b4-0bf9ce3f8960",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "hr_data",
      "label": "Schema Name",
      "name": "schema_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "hr_data",
      "label": "Schema Name",
      "name": "schema_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}